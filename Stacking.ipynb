{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bff4067",
   "metadata": {},
   "source": [
    "# 스태킹 - \"위스콘신 암 데이터 셋\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b23235f",
   "metadata": {},
   "source": [
    "## - \"개별 모델\" : KNN, 랜덤 포레스트, 결정 트리, 에이다 부스트\n",
    "## - \"최종 모델\" : 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dcbf81",
   "metadata": {},
   "source": [
    "## 1. 기본 스태킹 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8e571",
   "metadata": {},
   "source": [
    "## (1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cbe9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e4e322",
   "metadata": {},
   "source": [
    "## (2) 개별 모델들로 데이터 셋을 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b55dbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도 : 0.9211\n",
      "랜덤 포레스트 정확도 : 0.9649\n",
      "결정 트리 정확도 : 0.9035\n",
      "에이다부스트 정확도 : 0.9561\n"
     ]
    }
   ],
   "source": [
    "#개별 모델\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "#최종 모델\n",
    "lr_final = LogisticRegression(C=10)\n",
    "\n",
    "#개별 모델들 학습 및 예측\n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "\n",
    "print('KNN 정확도 : {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('랜덤 포레스트 정확도 : {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('결정 트리 정확도 : {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('에이다부스트 정확도 : {0:.4f}'.format(accuracy_score(y_test, ada_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be8e7c",
   "metadata": {},
   "source": [
    "## (3) 개별 모델들의 예측결과 컬럼들을 모두 옆으로 붙여 새로운 메타데이터를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f49090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa06439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "#transpose를 이용해 칼럼 별로 각 개별 모델의 예측값이 들어가도록 한다.\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b7e20",
   "metadata": {},
   "source": [
    "## (4) 최종 모델로 3.에서 만든 메타데이터 학습 후 테스트 데이터 예측하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b439ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도 : 0.8696\n"
     ]
    }
   ],
   "source": [
    "pred_train, pred_test, y_test_train, y_test_test = train_test_split(pred, y_test, test_size=0.2, random_state=0)\n",
    "\n",
    "lr_final.fit(pred_train, y_test_train)\n",
    "final = lr_final.predict(pred_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도 : {0:.4f}'.format(accuracy_score(y_test_test, final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a810c",
   "metadata": {},
   "source": [
    "random_state를 다른 값으로 하면 정확도가 올라가는데 0일때만 값이 낮다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1da4d",
   "metadata": {},
   "source": [
    "## 2. CV 셋 기반의 스태킹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf387687",
   "metadata": {},
   "source": [
    "방법이 조금 헷갈릴 수 있는데, 이해한 것을 그대로 써볼게. <br>\n",
    "우선 개별 모델이 여러개 있다고 가정하자. <br>\n",
    "이때 각각의 개별 모델들에게 다음 과정이 수행된다. <br>\n",
    "<p></p>\n",
    "우선 \"데이터 셋 = 학습 셋 + 테스트 셋\"으로 나누어진다. <br>\n",
    "<p></p>\n",
    "(step 1) 이때 Folds의 개수가 n이라면, 학습셋을 n개의 폴드로 나누고 그 중 한 폴드씩 검증 폴드로 이용하고 나머지 폴드는 학습 포드로 이용하여 학습 후 검증 폴드로 예측한 결과값을 모두 저장하면, 학습셋의 row의 개수와 동일한 예측결과값이 저장된다. <br> \n",
    "<p></p>\n",
    "(step 2) 그리고 각 학습폴드별 학습 수행 시 테스트 셋을 이용해서도 예측한 결과를 또 저장하고 모두 마치면 테스트 셋을 이용한 예측결과의 평균을 저장한다. 그러면 또한 테스트 셋의 row개수와 동일한 예측결과값이 나온다.<br>\n",
    "<p></p>\n",
    "각각의 개별 모델로 부터 위의 예측결과 값을 모두 모아, <br> \n",
    "step 1에서 나온 결과를 모두 옆으로 쌓아 최종모델 학습용 메타 데이터를 만든다. <br>\n",
    "step 2에서 나온 결과를 모두 옆으로 쌓아 최종모델 테스트용 메타 데이터를 만든다. <br>\n",
    "<p></p>\n",
    "해당 메타 데이터로 최종모델을 이용해 학습 / 예측을 진행한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3fa76f",
   "metadata": {},
   "source": [
    "## (1) 각 개별 모델 별 메타데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ee90631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#개별 모델의 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 만드는 함수\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    #지정된 폴드값으로 폴드생성\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    \n",
    "    #추후의 최종 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds)) # 이후 이 배열의 평균을 구해 columns이 1짜리로 다시 만들어 리턴할 것임\n",
    "    print(model.__class__.__name__, ' model 시작 ')\n",
    "    \n",
    "    #각 폴드마다 돌아가면서 학습폴드로 학습하고, 검증폴더로 예측한 결과를 train_fold_pred에 각 index에 찾아서 저장(KFold는 분리한 데이터를 index로 반환하기 때문)하고,\n",
    "    #학습된 모델을 테스트 셋으로 예측한 뒤 test_pred에 각 행(폴드번호)에 저장한다.\n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)): \n",
    "        print('\\t 폴드 세트 : ', folder_counter, ' 시작 ')\n",
    "        X_tr = X_train_n[train_index]\n",
    "        y_tr = y_train_n[train_index]\n",
    "        X_te = X_train_n[valid_index]\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "        \n",
    "    #학습된 모델을 테스트 셋으로 예측한 뒤 test_pred에 각 행(폴드번호)에 저장한 것을 행끼리 평균낸다.\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a60eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier  model 시작 \n",
      "\t 폴드 세트 :  0  시작 \n",
      "\t 폴드 세트 :  1  시작 \n",
      "\t 폴드 세트 :  2  시작 \n",
      "\t 폴드 세트 :  3  시작 \n",
      "\t 폴드 세트 :  4  시작 \n",
      "\t 폴드 세트 :  5  시작 \n",
      "\t 폴드 세트 :  6  시작 \n",
      "RandomForestClassifier  model 시작 \n",
      "\t 폴드 세트 :  0  시작 \n",
      "\t 폴드 세트 :  1  시작 \n",
      "\t 폴드 세트 :  2  시작 \n",
      "\t 폴드 세트 :  3  시작 \n",
      "\t 폴드 세트 :  4  시작 \n",
      "\t 폴드 세트 :  5  시작 \n",
      "\t 폴드 세트 :  6  시작 \n",
      "DecisionTreeClassifier  model 시작 \n",
      "\t 폴드 세트 :  0  시작 \n",
      "\t 폴드 세트 :  1  시작 \n",
      "\t 폴드 세트 :  2  시작 \n",
      "\t 폴드 세트 :  3  시작 \n",
      "\t 폴드 세트 :  4  시작 \n",
      "\t 폴드 세트 :  5  시작 \n",
      "\t 폴드 세트 :  6  시작 \n",
      "AdaBoostClassifier  model 시작 \n",
      "\t 폴드 세트 :  0  시작 \n",
      "\t 폴드 세트 :  1  시작 \n",
      "\t 폴드 세트 :  2  시작 \n",
      "\t 폴드 세트 :  3  시작 \n",
      "\t 폴드 세트 :  4  시작 \n",
      "\t 폴드 세트 :  5  시작 \n",
      "\t 폴드 세트 :  6  시작 \n"
     ]
    }
   ],
   "source": [
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 7)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a8afc",
   "metadata": {},
   "source": [
    "## (2) 각 개별 모델별로 만든 메타데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "030321ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 shape :  (455, 30) 원본 테스트 피처 shape :  (114, 30)\n",
      "스태킹 학습 피처 데이터 shape :  (455, 4) 스태킹 테스트 피처 데이터 shape :  (114, 4)\n"
     ]
    }
   ],
   "source": [
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "print('원본 학습 피처 데이터 shape : ', X_train.shape, '원본 테스트 피처 shape : ', X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 shape : ', Stack_final_X_train.shape, '스태킹 테스트 피처 데이터 shape : ', Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd10bc8a",
   "metadata": {},
   "source": [
    "각각의 개별 모델의 에측결과를 합쳤으므로 메타데이터의 column개수는 개별모델의 개수인 4개이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789aa92",
   "metadata": {},
   "source": [
    "## (3) 최종 모델로 메타데이터 학습 / 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02f6ce1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도 : 0.9737\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도 : {0:.4f}'.format(accuracy_score(y_test, stack_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eefccd",
   "metadata": {},
   "source": [
    "# 파라미터 튜닝?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9e2bb",
   "metadata": {},
   "source": [
    "여기서는 파라미터 튜닝을 실시하지 않았지만, 일반적으로 파라미터 튜닝을 최적으로 해놓고 스태킹 앙상블 기법을 이용한다. 이때 파라미터를 튜닝한다는 것은 개별 모델의 파라미터를 최적으로 튜닝하는 것을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6103248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
